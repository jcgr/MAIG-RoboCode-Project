\section{Introduction}
\label{01}
This paper was written as part of a project for the "Modern AI in Games" course on the Games Technology track at the IT-University of Copenhagen. The source code and test data are available on our repository\footnote{https://github.com/jcgr/MAIG-RoboCode-Project} on Github.

The Monte-Carlo Tree Search (MCTS) algorithm is commonly used in games to search for the best path in a game tree. The algorithm is generalizable to most games as it, in its base form, "does not require any strategic or tactical knowledge about the given domain to make reasonable decisions"\cite{mctsai}. This can change drastically, however, when MCTS is introduced to a game where states of the game are only partially observable and where there is no single best strategy that the algorithm can assume that an adversary is using. 

In this paper, we will test our hypothesis that partially observable games against complex adversaries will make MCTS perform poorly against simpler adversaries. In order to do so, we will discuss how MCTS works, what makes a game partially observable, and how the mechanics of our test game, Robocode, may influence the performance of a MCTS game playing algorithm. We will then present the algorithm we have used to test against sample robots in Robocode, followed by a reporting of the results and a discussion of the potential changes that could be made to the algorithm.